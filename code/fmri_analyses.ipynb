{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIOP1 analyses\n",
    "Here, we compute some first-level and group analyses of the PIOP1 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from nistats.first_level_model import FirstLevelModel, make_first_level_design_matrix, run_glm\n",
    "from nistats.contrasts import _fixed_effect_contrast, compute_contrast\n",
    "from nistats.hemodynamic_models import glover_hrf\n",
    "from nistats.design_matrix import _cosine_drift\n",
    "from nilearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.plotting import view_img\n",
    "from nilearn import plotting, signal, masking, image\n",
    "from glob import glob\n",
    "from nilearn import masking\n",
    "from nideconv import ResponseFitter\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from patsy import DesignInfo\n",
    "from scipy.interpolate import interp1d\n",
    "from joblib import Parallel, delayed\n",
    "from warnings import warn\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(threadName)-8s] [%(levelname)-7.7s]  %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    \"\"\" Dataset class for easy fMRI analyses with fMRIPREP outputs. \"\"\"\n",
    "    def __init__(self, bids_dir, sub, n_jobs=1, log_level=logging.INFO):\n",
    "        \"\"\" Initializes Analysis object.\n",
    "        \n",
    "        parameters\n",
    "        ----------\n",
    "        bids_dir : str\n",
    "            Path to BIDS directory\n",
    "        sub : str\n",
    "            Subject-identifier (e.g., '01')\n",
    "        n_jobs : int\n",
    "            Number of jobs to use for computations\n",
    "        \"\"\"\n",
    "        self.sub = sub\n",
    "        self.bids_dir = op.join(op.abspath(bids_dir), f'sub-{sub}')\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        self.deriv_dir = op.join(bids_dir, 'derivatives')\n",
    "        self.fp_dir = op.join(self.deriv_dir, 'fmriprep', f'sub-{sub}')\n",
    "        self.fs_dir = op.join(self.deriv_dir, 'freesurfer', f'sub-{sub}')\n",
    "        self.physio_dir = op.join(self.deriv_dir, 'physiology', f'sub-{sub}')\n",
    "        self.logger = logging.getLogger('dataset')\n",
    "        self.logger.setLevel(log_level)\n",
    "\n",
    "    def create_taskset(self, task, space, acq=None, ses=False, hemi='R', reference_run=-1,\n",
    "                       use_gm_mask=True, gm_threshold=0.5):\n",
    "        \"\"\" Creates a 'taskset'. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        task : str\n",
    "            Name of task\n",
    "        space : str\n",
    "            Name of space to analyze data in (e.g., 'T1w', 'fsnative')\n",
    "        acq : str\n",
    "            Name of acquisition parameter (in filenames, e.g., acq-Mm3)\n",
    "        ses : bool\n",
    "            Whether the taskset is split over multiple sessions\n",
    "        hemi : str\n",
    "            Either 'L' or 'R'; only used when space == 'fsnative'\n",
    "        \"\"\"\n",
    "        base_str = f'sub-{self.sub}'\n",
    "        if ses:\n",
    "            base_str += f'_ses-*'\n",
    "            this_fp_dir = op.join(self.fp_dir, 'ses-*')\n",
    "            this_bids_dir = op.join(self.bids_dir, 'ses-*')\n",
    "            this_physio_dir = op.join(self.physio_dir, 'ses-*')\n",
    "        else:\n",
    "            this_fp_dir = self.fp_dir\n",
    "            this_bids_dir = self.bids_dir\n",
    "            this_physio_dir = self.physio_dir\n",
    "\n",
    "        base_str += f'_task-{task}'\n",
    "\n",
    "        if acq is not None:\n",
    "            base_mri_str = f'{base_str}_acq-{acq}'\n",
    "        else:\n",
    "            base_mri_str = base_str\n",
    "        \n",
    "        self.logger.info(f\"Proceeding with base MRI string '{base_mri_str}'\")\n",
    "        \n",
    "        conf_str = '_desc-confounds_regressors.tsv'\n",
    "        all_confs = sorted(glob(op.join(this_fp_dir, 'func', f'{base_mri_str}*{conf_str}')))\n",
    "        self.logger.info(f\"Found {len(all_confs)} confound files.\")\n",
    "        \n",
    "        if 'fs' in space:\n",
    "            func_str = f'_space-{space}_hemi-{hemi}.func.gii'\n",
    "        else:\n",
    "            func_str = f'_space-{space}_desc-preproc_bold.nii.gz'\n",
    "        \n",
    "        all_funcs = sorted(glob(op.join(this_fp_dir, 'func', f'{base_mri_str}*{func_str}')))\n",
    "        self.logger.info(f\"Found {len(all_funcs)} functional file(s).\")\n",
    "        \n",
    "        if 'fs' not in space:        \n",
    "            mask_str = f'_space-{space}_desc-brain_mask.nii.gz'\n",
    "            all_masks = sorted(glob(op.join(this_fp_dir, 'func', f'{base_mri_str}*{mask_str}')))\n",
    "            self.logger.info(f\"Found {len(all_masks)} functional mask(s).\")\n",
    "\n",
    "            tmp = nib.load(all_masks[reference_run])\n",
    "            for i, mask in enumerate(all_masks):  # check if we need to resapmle\n",
    "                if not np.all(nib.load(mask).affine == tmp.affine):\n",
    "                    self.logger.warning(\n",
    "                        f\"WARNING: mask of run {i} has a different affine than \"\n",
    "                        f\"the reference run {reference_run}! Going to resample ...\"\n",
    "                    )\n",
    "                    all_masks[i] = image.resample_img(\n",
    "                        mask,\n",
    "                        target_affine=tmp.affine,\n",
    "                        target_shape=tmp.shape,\n",
    "                        interpolation='nearest'\n",
    "                    )\n",
    "                \n",
    "            mask = masking.intersect_masks(all_masks, threshold=0.5)\n",
    "            if use_gm_mask:\n",
    "                if 'MNI' in space:\n",
    "                    gm_mask = op.join(\n",
    "                        self.fp_dir, 'anat',\n",
    "                        f'sub-{self.sub}_space-{space}_label-GM_probseg.nii.gz'\n",
    "                    )\n",
    "                else:\n",
    "                    gm_mask = op.join(\n",
    "                        self.fp_dir, 'anat',\n",
    "                        f'sub-{self.sub}_label-GM_probseg.nii.gz'\n",
    "                    )\n",
    "                \n",
    "                self.logger.info(f\"Adding GM mask: {gm_mask}\")\n",
    "                    \n",
    "                gm_img = nib.load(gm_mask)\n",
    "                gm_mask = nib.Nifti1Image((gm_img.get_data() > gm_threshold).astype(int), affine=gm_img.affine)\n",
    "                \n",
    "                if not np.all(gm_mask.affine == tmp.affine):\n",
    "                    self.logger.info(\n",
    "                        \"Resampling GM mask because has a different affine than the functional masks.\"\n",
    "                    )\n",
    "                    gm_mask = image.resample_img(\n",
    "                        gm_mask,\n",
    "                        target_affine=tmp.affine,\n",
    "                        target_shape=tmp.shape,\n",
    "                        interpolation='nearest'\n",
    "                    )\n",
    "\n",
    "                mask = masking.intersect_masks([mask, gm_mask], threshold=1)\n",
    "        else:\n",
    "            mask = None  # no mask for surface files!\n",
    "            gm_mask = None\n",
    "\n",
    "        event_str = '_events.tsv'\n",
    "        all_events = sorted(glob(op.join(this_bids_dir, 'func', f'{base_mri_str}*{event_str}')))\n",
    "        self.logger.info(f\"Found {len(all_events)} event file(s).\")\n",
    "        \n",
    "        if len(all_funcs) != len(all_events) != len(all_confs):\n",
    "            self.logger.warning(\n",
    "                f\"Found {len(all_funcs)} funcs but {len(all_events)} events and {len(all_confs)} confs!\"\n",
    "            )\n",
    "        \n",
    "        ricor_str = '_desc-retroicor_regressors.tsv'\n",
    "        all_ricors = sorted(glob(op.join(this_physio_dir, 'physio', f'{base_mri_str}*{ricor_str}')))\n",
    "        self.logger.info(f\"Found {len(all_ricors)} RETROICOR file(s).\")\n",
    "        \n",
    "        if len(all_ricors) != len(all_funcs):\n",
    "            self.logger.warning(\n",
    "                f\"Found {len(all_funcs)} funcs but only {len(all_ricors)} RETROICOR files!\"\n",
    "            )\n",
    "        \n",
    "        data = dict(funcs=dict(), events=dict(), confs=dict(), ricors=dict(), mask=mask)\n",
    "        for run, (func, event, conf) in enumerate(zip(all_funcs, all_events, all_confs)):\n",
    "                \n",
    "            for name, elem in zip(['funcs', 'events', 'confs'], [func, event, conf]):\n",
    "                data[name][run] = elem\n",
    "                \n",
    "            tmp_base = op.basename(conf.split(conf_str)[0])\n",
    "            for r in all_ricors:\n",
    "                if tmp_base in r:\n",
    "                    data['ricors'][run] = r\n",
    "            \n",
    "        if use_gm_mask:\n",
    "            data['gm_mask'] = gm_mask\n",
    "        \n",
    "        n_comp_runs = len(data['funcs'])\n",
    "        self.logger.info(f\"Found {n_comp_runs} complete runs for task {task}.\")\n",
    "\n",
    "        ts = Taskset(task=task, space=space, n_jobs=self.n_jobs, log_level=self.logger.level, **data)\n",
    "        setattr(self, task, ts)\n",
    "\n",
    "    def visualize(self, statmap, space='fsnative', threshold=0, hemi='R', mask=None, **plot_args):\n",
    "        \"\"\" Visualizes a statmap on an image/surface background. \"\"\"\n",
    "        if 'fs' in space and isinstance(statmap, nib.Nifti1Image):\n",
    "            raise ValueError(\"Statmap is an image, but space is fs* something ...\")\n",
    "        \n",
    "        bg = 'surface' if 'fs' in space else 'volume'\n",
    "        self.logger.info(f\"Visualizing statmap on {bg} ...\")\n",
    "        if 'fs' in space:\n",
    "            fs_base = op.dirname(self.fs_dir)\n",
    "            if space == 'fsnative':\n",
    "                fs_id = f'sub-{self.sub}'\n",
    "            else:\n",
    "                fs_id = space\n",
    "                    \n",
    "            return plotting.view_surf(\n",
    "                surf_mesh=op.join(fs_base, fs_id, 'surf', f'{hemi.lower()}h.inflated'),\n",
    "                surf_map=statmap,\n",
    "                bg_map=op.join(fs_base, fs_id, 'surf', f'{hemi.lower()}h.sulc'),\n",
    "                threshold=threshold,\n",
    "                **plot_args\n",
    "            )\n",
    "        else:\n",
    "            \n",
    "            if mask is not None:\n",
    "                statmap = masking.unmask(statmap, mask)\n",
    "\n",
    "            if space == 'T1w':\n",
    "                bg = op.join(self.fp_dir, 'anat', f'sub-{self.sub}_desc-preproc_T1w.nii.gz')\n",
    "            else:\n",
    "                bg = 'MNI152'\n",
    "\n",
    "                \n",
    "            return plotting.view_img(\n",
    "                stat_map_img=statmap,\n",
    "                bg_img=bg,\n",
    "                threshold=threshold,\n",
    "                **plot_args\n",
    "            )\n",
    "\n",
    "\n",
    "class Taskset:\n",
    "    \n",
    "    def __init__(self, task, space, funcs, confs, events, ricors, mask, gm_mask=None, n_jobs=1, log_level=20):\n",
    "        \"\"\" Initializes a taskset object. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        task : str\n",
    "            Name of task\n",
    "        space : str\n",
    "            Name of space (e.g., T1w, fsnative)\n",
    "        funcs : list\n",
    "            List of func files\n",
    "        confs : list\n",
    "            List of conf files\n",
    "        events : list\n",
    "            List of event files\n",
    "        ricors : list\n",
    "            List of retroicor files\n",
    "        mask : Nifti1Image or None\n",
    "            Mask for volume files, or None when dealing with surface files\n",
    "        n_jobs : int\n",
    "            Number of jobs to use for computations\n",
    "        \"\"\"\n",
    "        self.task = task\n",
    "        self.space = space\n",
    "        self.funcs = funcs\n",
    "        self.confs = confs\n",
    "        self.events = events\n",
    "        self.ricors = ricors\n",
    "        self.mask = mask\n",
    "        self.gm_mask = gm_mask\n",
    "        self.n_jobs = n_jobs\n",
    "        self.n_runs = len(self.funcs)\n",
    "        self.preprocessed = False\n",
    "        self.glm = None\n",
    "        self.tr = []\n",
    "        self.logger = logging.getLogger(task)\n",
    "        self.logger.setLevel(log_level)\n",
    "\n",
    "    def __repr__(self):\n",
    "        msg = f\"{self.task} taskset containg data of {self.n_runs} runs\"\n",
    "        return msg\n",
    "    \n",
    "    def preprocess(self, smoothing_fwhm=None, hp_cutoff=None, add_motion_outliers=True, add_ricor=True,\n",
    "                   conf_vars=None, df_filter=None, slice_time_ref=0.5, regress_confounds=False):\n",
    "        \n",
    "        self.logger.info(f\"Starting preprocessing for task {self.task}.\")\n",
    "        if conf_vars is None:\n",
    "            conf_vars = []\n",
    "\n",
    "        if 'fs' in self.space:\n",
    "            for i in range(len(self.funcs)):\n",
    "                this_tr = nib.load(self.funcs[i]).darrays[0].metadata['TimeStep']\n",
    "                self.tr.append(np.float(this_tr) / 1000)\n",
    "        else:\n",
    "            self.tr = [nib.load(self.funcs[i]).header['pixdim'][4]\n",
    "                       for i in range(len(self.funcs))]\n",
    "            \n",
    "        self.tr = np.array(self.tr)\n",
    "        if not np.all(self.tr[0] == self.tr):\n",
    "            self.logger.warning(\"Not all TRs across runsare the same ({self.tr})!\")\n",
    "        \n",
    "        if add_ricor and len(self.ricors) == 0:\n",
    "            self.logger.warning(\"No ricor file, so setting add_ricor to False.\")\n",
    "            add_ricor = False\n",
    "        \n",
    "        out = Parallel(n_jobs=self.n_jobs)(delayed(_run_preproc_in_parallel)(\n",
    "                run=run,\n",
    "                event=self.events[run],\n",
    "                conf=self.confs[run],\n",
    "                func=self.funcs[run],\n",
    "                ricor=self.ricors[run] if add_ricor else None,\n",
    "                task=self.task,\n",
    "                space=self.space,\n",
    "                conf_vars=conf_vars,\n",
    "                mask=self.mask,\n",
    "                smoothing_fwhm=smoothing_fwhm,\n",
    "                hp_cutoff=hp_cutoff,\n",
    "                add_motion_outliers=add_motion_outliers,\n",
    "                df_filter=df_filter,\n",
    "                tr=self.tr[run],\n",
    "                slice_time_ref=slice_time_ref,\n",
    "                logger=self.logger\n",
    "            ) for run in range(self.n_runs)\n",
    "        )\n",
    "        \n",
    "        prep_out = dict(\n",
    "            func_ts=[o[0] for o in out],\n",
    "            confs=[o[1] for o in out],\n",
    "            events=[o[2] for o in out]\n",
    "        )        \n",
    "        \n",
    "        if regress_confounds:\n",
    "            clean = []\n",
    "            for i, func in enumerate(prep_out['func_ts']):\n",
    "                self.logger.info(f\"Regressing out confounds for run {i+1} ...\")\n",
    "                sig = signal.clean(\n",
    "                    signals=func,\n",
    "                    confounds=prep_out['confs'][i].values,\n",
    "                    standardize=False,\n",
    "                    detrend=False\n",
    "                )\n",
    "                clean.append(sig)\n",
    "            prep_out['func_clean'] = clean\n",
    "        \n",
    "        self.preprocessed = True\n",
    "        self.preproc = prep_out    \n",
    "\n",
    "    def compute_tsnr(self, run=None, mean_only=False, std_only=False):\n",
    "        \"\"\" Computes tsnr (or mean/std) image of the (mean) functional data. \"\"\"\n",
    "\n",
    "        self.logger.info(\"Computing TSNR.\")\n",
    "        if mean_only and std_only:\n",
    "            raise ValueError(\"Cannot return mean only and std only!\")\n",
    "\n",
    "        if run is None:\n",
    "            n_runs = len(self.preproc['func_ts'])\n",
    "        else:\n",
    "            n_runs = 1\n",
    "        \n",
    "        stat = np.zeros((n_runs, self.preproc['func_ts'][0].shape[-1]))\n",
    "        for run in range(n_runs):\n",
    "            func = self.preproc['func_ts'][run]\n",
    "            if mean_only:\n",
    "                this_stat = func.mean(axis=0)\n",
    "            elif std_only:\n",
    "                this_stat = func.std(axis=0)\n",
    "            else:\n",
    "                this_stat = func.mean(axis=0) / func.std(axis=0)\n",
    "            \n",
    "            this_stat[np.isnan(this_stat)] = 0\n",
    "            stat[run, :] = this_stat\n",
    "        \n",
    "        mean_stat = stat.mean(axis=0)\n",
    "        if self.mask is not None:\n",
    "            mean_stat = masking.unmask(mean_stat, self.mask)\n",
    "        \n",
    "        return mean_stat\n",
    "    \n",
    "    def glm_detect(self, dm=None, hrf_model='glover', noise_model='ols', osf=30,\n",
    "                   slice_time_ref=0.5, mask=None, rf_condition=None):\n",
    "\n",
    "        if not self.preprocessed:\n",
    "            raise ValueError(\"Data was not preprocessed yet!\")\n",
    "\n",
    "        self.logger.info(f\"Starting GLM estimation for task {self.task}.\")\n",
    "\n",
    "        glm_out = Parallel(n_jobs=self.n_jobs)(delayed(_run_glm_in_parallel)(\n",
    "            dm=dm,\n",
    "            run=run,\n",
    "            event=self.preproc['events'][run],\n",
    "            conf=self.preproc['confs'][run],\n",
    "            func=self.preproc['func_ts'][run],\n",
    "            hrf_model=hrf_model,\n",
    "            noise_model=noise_model,\n",
    "            tr=self.tr[run],\n",
    "            osf=osf,\n",
    "            slice_time_ref=slice_time_ref,\n",
    "            mask=mask,\n",
    "            rf_condition=rf_condition,\n",
    "            logger=self.logger\n",
    "            ) for run in range(self.n_runs)\n",
    "        )\n",
    "\n",
    "        self.glm = dict(\n",
    "            labels=[run[0] for run in glm_out],\n",
    "            results=[run[1] for run in glm_out],\n",
    "            dms=[run[2] for run in glm_out],\n",
    "            mask=mask\n",
    "        )\n",
    "        \n",
    "        if len(glm_out[0]) == 4:\n",
    "            self.glm['hrfs'] = [run[3] for run in glm_out]\n",
    "\n",
    "    def compute_fxe_contrast(self, contrast_def, stat_type='t', run=None, output_type='z_score'):\n",
    "        \"\"\" Computes a fixed effect across multiple runs. \"\"\"\n",
    "        \n",
    "        self.logger.info(f\"Computing contrast: {contrast_def} for task {self.task} ...\")\n",
    "        if self.glm is None:\n",
    "            raise ValueError(\"GLM has not been run yet!\")\n",
    "\n",
    "        if run is None:\n",
    "            results = self.glm['results']\n",
    "            labels = self.glm['labels']\n",
    "            dms = self.glm['dms']\n",
    "            design_info = DesignInfo(dms[0].columns.tolist())\n",
    "        else:\n",
    "            results = self.glm['results'][run]\n",
    "            labels = self.glm['labels'][run]\n",
    "            dms = self.glm['dms'][run]\n",
    "            design_info = DesignInfo(dms.columns.tolist())\n",
    "\n",
    "        if isinstance(contrast_def, (np.ndarray, str)):\n",
    "            con_vals = [contrast_def]\n",
    "        elif isinstance(contrast_def, (list, tuple)):\n",
    "            con_vals = contrast_def\n",
    "        else:\n",
    "            raise ValueError('contrast_def must be an array or str or list of'\n",
    "                             ' (array or str)')\n",
    "\n",
    "        for cidx, con in enumerate(con_vals):\n",
    "            if not isinstance(con, np.ndarray):\n",
    "                con_vals[cidx] = design_info.linear_constraint(con).coefs\n",
    "\n",
    "        if run is None:\n",
    "            contrast = _fixed_effect_contrast(labels, results, con_vals, stat_type)\n",
    "        else:\n",
    "            contrast = compute_contrast(labels, results, con_vals, stat_type)\n",
    "\n",
    "        values = getattr(contrast, output_type)()\n",
    "        if self.mask is not None:\n",
    "            return masking.unmask(values, self.mask)\n",
    "        else:\n",
    "            return values\n",
    "        \n",
    "    def plot_design(self, exclude_confs=True):\n",
    "        n_runs = len(self.glm['dms'])\n",
    "        fig, ax = plt.subplots(nrows=n_runs, figsize=(15, 4 * n_runs))\n",
    "        for run in range(n_runs):\n",
    "            \n",
    "            if n_runs != 1:\n",
    "                this_ax = ax[run]\n",
    "            else:\n",
    "                this_ax = ax\n",
    "            \n",
    "            this_dm = self.glm['dms'][run].drop('constant', axis=1)\n",
    "            if exclude_confs:\n",
    "                this_dm = this_dm.drop(self.preproc['confs'][run].columns, axis=1)\n",
    "\n",
    "            this_ax.plot(this_dm.values)\n",
    "            this_ax.set_title(f\"Run {run+1}\")\n",
    "            if run == 0:\n",
    "                this_ax.legend(this_dm.columns)\n",
    "        \n",
    "\n",
    "def _run_preproc_in_parallel(run, event, conf, func, ricor, task, space, conf_vars, mask, hp_cutoff,\n",
    "                             add_motion_outliers, smoothing_fwhm, df_filter, slice_time_ref, tr, logger):\n",
    "    \n",
    "    logger.info(f\"Preprocessing run {run+1} ...\")\n",
    "    \n",
    "    if 'fs' in space:\n",
    "        func_ts = np.vstack([d.data[np.newaxis, :] for\n",
    "                             d in nib.load(func).darrays])\n",
    "    else:                       \n",
    "        if not np.all(nib.load(func).affine == mask.affine):\n",
    "            print(f\"Resampling run {run+1} to mask affine, because they are different\")\n",
    "            func = image.resample_img(func, target_affine=mask.affine, target_shape=mask.shape)\n",
    "                                                               \n",
    "        func_ts = masking.apply_mask(\n",
    "            imgs=func,\n",
    "            mask_img=mask,\n",
    "            smoothing_fwhm=smoothing_fwhm\n",
    "        )\n",
    "\n",
    "    n_vols = func_ts.shape[0]\n",
    "    start_time = slice_time_ref * tr\n",
    "    end_time = (n_vols - 1 + slice_time_ref) * tr\n",
    "    frame_times = np.linspace(start_time, end_time, n_vols)\n",
    "\n",
    "    event = pd.read_csv(event, sep='\\t')\n",
    "    if df_filter is not None: \n",
    "        event = df_filter(event)\n",
    "\n",
    "    conf = pd.read_csv(conf, sep='\\t')    \n",
    "    all_conf_vars = conf_vars\n",
    "\n",
    "    if add_motion_outliers:\n",
    "        mo = [col for col in conf.columns if 'motion_outlier' in col]\n",
    "        if len(mo) > 0:\n",
    "            logger.info(f\"Adding {len(mo)} motion outliers to design for run {run+1}.\")\n",
    "        all_conf_vars += mo\n",
    "\n",
    "    if hp_cutoff is None:\n",
    "        all_conf_vars += [col for col in conf.columns if 'cosine' in col]\n",
    "        conf = conf.loc[:, all_conf_vars].fillna(0)\n",
    "        conf = pd.concat((conf, cos_df), axis=1)\n",
    "    else:\n",
    "        conf = conf.loc[:, all_conf_vars].fillna(0)\n",
    "        cos = _cosine_drift(hp_cutoff, frame_times)[:, :-1]\n",
    "        cos_names = [f'cosine{ic}'.zfill(3) for ic in range(cos.shape[1])]\n",
    "        cos_df = pd.DataFrame(data=cos, columns=cos_names, index=conf.index)\n",
    "        conf = pd.concat((conf, cos_df), axis=1)\n",
    "    \n",
    "    if ricor is not None:\n",
    "        ricor_df = pd.read_csv(ricor, sep='\\t')\n",
    "        conf = pd.concat((conf, ricor_df), axis=1)\n",
    "    \n",
    "    return func_ts, conf, event\n",
    "\n",
    "\n",
    "def _run_glm_in_parallel(dm, run, event, conf, func, hrf_model, noise_model, tr, osf, slice_time_ref, \n",
    "                         mask, rf_condition, logger):\n",
    "\n",
    "    logger.info(f\"Fitting GLM to run {run+1} ...\")\n",
    "    n_vols = func.shape[0]\n",
    "    start_time = slice_time_ref * tr\n",
    "    end_time = (n_vols - 1 + slice_time_ref) * tr\n",
    "    frame_times = np.linspace(start_time, end_time, n_vols)\n",
    "\n",
    "    if mask is not None:\n",
    "        func = func[:, mask.ravel()]\n",
    "\n",
    "    if dm is not None:\n",
    "        logger.info(\"Design-matrix was supplied, so fitting GLM immediately.\")\n",
    "        dm.index = frame_times\n",
    "        conf.index = dm.index\n",
    "        glm_results = run_glm(func, dm.values, noise_model=noise_model)\n",
    "        return glm_results[0], glm_results[1], dm\n",
    "\n",
    "    logger.info(f\"Using default Nistats HRF model '{hrf_model}'.\")\n",
    "    dm = make_first_level_design_matrix(\n",
    "        frame_times=frame_times,\n",
    "        events=event,\n",
    "        drift_model=None,\n",
    "        hrf_model=hrf_model,\n",
    "        fir_delays=None\n",
    "    )\n",
    "\n",
    "    conf.index = dm.index\n",
    "    dm = pd.concat((dm, conf), axis=1)\n",
    "    glm_results = run_glm(func, dm.values, noise_model=noise_model)\n",
    "    return glm_results[0], glm_results[1], dm\n",
    "\n",
    "\n",
    "def _merge_regression_results(lab, res, labels, results, n_vox):\n",
    "    \n",
    "    labels.append(lab)\n",
    "    if lab not in results:\n",
    "        results[lab] = res[lab]\n",
    "        for attr in ['norm_resid', 'resid']:\n",
    "            setattr(results[lab], attr, getattr(results[lab], attr).squeeze())\n",
    "    else:\n",
    "        for attr1d in ['SSE', 'logL', 'dispersion']:\n",
    "            existing = getattr(results[lab], attr1d)\n",
    "            new = getattr(res[lab], attr1d)\n",
    "            concat = np.append(existing, new)\n",
    "            setattr(results[lab], attr1d, concat)\n",
    "            \n",
    "        for attr2d in ['Y', 'norm_resid', 'resid', 'theta', 'wY', 'wresid']:    \n",
    "            existing = getattr(results[lab], attr2d)\n",
    "            new = getattr(res[lab], attr2d)\n",
    "            concat = np.c_[existing, new]\n",
    "            setattr(results[lab], attr2d, concat)\n",
    "            \n",
    "    return labels, results\n",
    "\n",
    "\n",
    "def compute_rfx_contrast(imgs, design_matrix, contrast_def, mask=None, noise_model='ols', stat_type='t', output_type='z_score'):\n",
    "\n",
    "    design_info = DesignInfo(design_matrix.columns.tolist())\n",
    "    if isinstance(imgs, list):\n",
    "        Y = np.stack([i.get_data() for i in imgs]).reshape(len(imgs), -1)        \n",
    "    elif isinstance(imgs, np.ndarray):\n",
    "        Y = imgs\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown format for Y ({type(imgs)}).\")\n",
    "\n",
    "    X = design_matrix.values\n",
    "    labels, results = run_glm(Y, X, noise_model=noise_model)\n",
    "\n",
    "    if isinstance(contrast_def, (np.ndarray, str)):\n",
    "        con_vals = [contrast_def]\n",
    "    elif isinstance(contrast_def, (list, tuple)):\n",
    "        con_vals = contrast_def\n",
    "    else:\n",
    "        raise ValueError('contrast_def must be an array or str or list of'\n",
    "                         ' (array or str)')\n",
    "\n",
    "    for cidx, con in enumerate(con_vals):\n",
    "        if not isinstance(con, np.ndarray):\n",
    "            con_vals[cidx] = design_info.linear_constraint(con).coefs\n",
    "\n",
    "    contrast = compute_contrast(labels, results, con_vals, stat_type)\n",
    "\n",
    "    values = getattr(contrast, output_type)()\n",
    "    if isinstance(imgs, list):\n",
    "        values = nib.Nifti1Image(values.reshape(imgs[0].shape), affine=imgs[0].affine)\n",
    "\n",
    "    return values\n",
    "\n",
    "\n",
    "def plot_surface(data, mesh='infl', hemi='right', bg='sulc', space='fsaverage5', threshold=0):\n",
    "    fs = datasets.fetch_surf_fsaverage(mesh=space, data_dir=None)\n",
    "    return plotting.view_surf(\n",
    "        surf_mesh=getattr(fs, f'{mesh}_{hemi}'),\n",
    "        surf_map=data,\n",
    "        bg_map=getattr(fs, f'{bg}_{hemi}'),\n",
    "        threshold=threshold\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def preproc_df(df, col):\n",
    "    df.loc[:, 'trial_type'] = df.loc[:, col]\n",
    "    df = df.loc[~df['trial_type'].isna(), :]\n",
    "    return df\n",
    "\n",
    "\n",
    "def _parallel_fit(sub, task, space, acq, hemi, df_filter, con):\n",
    "\n",
    "    ds = Dataset(bids_dir='..', sub=sub, n_jobs=1, log_level=30)\n",
    "    ds.create_taskset(\n",
    "        task=task,\n",
    "        space=space,\n",
    "        acq=acq,\n",
    "        ses=False,\n",
    "        hemi=hemi,\n",
    "        use_gm_mask=True,\n",
    "        gm_threshold=0.3\n",
    "    )\n",
    "    getattr(ds, task).preprocess(\n",
    "        smoothing_fwhm=5,\n",
    "        hp_cutoff=0.01,\n",
    "        conf_vars=None,\n",
    "        df_filter=df_filter,\n",
    "        slice_time_ref=0.5,\n",
    "        add_ricor=True,\n",
    "        add_motion_outliers=False,\n",
    "        regress_confounds=False\n",
    "    )\n",
    "    getattr(ds, task).glm_detect(\n",
    "        dm=None,\n",
    "        hrf_model='glover',\n",
    "        noise_model='ols',\n",
    "        osf=30,\n",
    "        slice_time_ref=0.5,\n",
    "        mask=None,\n",
    "        rf_condition=None\n",
    "    )\n",
    "    try:\n",
    "        img = getattr(ds, task).compute_fxe_contrast(\n",
    "            contrast_def=con,\n",
    "            stat_type='t',\n",
    "            run=None,\n",
    "            output_type='effect_size'\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b2c9d135104d8db351710378329e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=202), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TASK = 'gstroop'\n",
    "subs = glob(f'../derivatives/fmriprep/sub-*/func/sub-*_task-{TASK}_acq-mb3_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz')\n",
    "subs = [op.basename(op.dirname(op.dirname(sub))).split('-')[1] for sub in subs]\n",
    "SPACE = ''#'MNI152NLin2009cAsym'\n",
    "ACQ = 'mb3'\n",
    "HEMI = 'R'\n",
    "DF_FILTER = partial(preproc_df, col='trial_type')\n",
    "CON = 'Anger - Joy'\n",
    "\n",
    "imgs = Parallel(n_jobs=40)(delayed(_parallel_fit)(\n",
    "    sub, TASK, SPACE, ACQ, HEMI, DF_FILTER, CON\n",
    ") for sub in tqdm_notebook(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1fca443178fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdesign_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcontrast_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'icept'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mstat_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0mplot_surface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e295311417d2>\u001b[0m in \u001b[0;36mcompute_rfx_contrast\u001b[0;34m(imgs, design_matrix, contrast_def, mask, noise_model, stat_type, output_type)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0mdesign_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDesignInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesign_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "dm = pd.DataFrame({'icept': np.ones(len(imgs))})\n",
    "out = compute_rfx_contrast(\n",
    "    imgs=imgs,#np.vstack(imgs),\n",
    "    design_matrix=dm,\n",
    "    contrast_def='icept',\n",
    "    stat_type='t'\n",
    ")\n",
    "plot_surface(out, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'emorecognition'\n",
    "subs = sorted(glob(f'../derivatives/fmriprep/sub-*/func/sub-*_task-{TASK}*_space-T1w_desc-preproc_bold.json'))[:200]\n",
    "subs = [op.basename(op.dirname(op.dirname(sub))).split('-')[1] for sub in subs]\n",
    "SPACE = 'fsaverage5'\n",
    "ACQ = 'seq'\n",
    "HEMI = 'R'\n",
    "DF_FILTER = partial(preproc_df, col='response_hand')\n",
    "CON = 'left - right'\n",
    "\n",
    "imgs = Parallel(n_jobs=15)(delayed(_parallel_fit)(\n",
    "  sub, TASK, SPACE, ACQ, HEMI, DF_FILTER, CON\n",
    ") for sub in tqdm_notebook(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [i for i in imgs if i is not None]\n",
    "ds = Dataset(bids_dir='..', sub=subs[0], n_jobs=1, log_level=30)\n",
    "dm = pd.DataFrame({'icept': np.ones(len(imgs))})\n",
    "out = compute_rfx_contrast(\n",
    "    imgs=np.vstack(imgs),\n",
    "    design_matrix=dm,\n",
    "    contrast_def='icept',\n",
    "    stat_type='t'\n",
    ")\n",
    "\n",
    "plot_surface(out, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'gstroop'\n",
    "subs = glob(f'../derivatives/fmriprep/sub-*/func/sub-*_task-{TASK}*_space-T1w_desc-preproc_bold.json')[:200]\n",
    "subs = [op.basename(op.dirname(op.dirname(sub))).split('-')[1] for sub in subs]\n",
    "SPACE = 'fsaverage5'\n",
    "ACQ = 'seq'\n",
    "HEMI = 'R'\n",
    "DF_FILTER = partial(preproc_df, col='response_accuracy')\n",
    "CON = 'incorrect - correct'\n",
    "\n",
    "imgs = Parallel(n_jobs=10)(delayed(_parallel_fit)(\n",
    "  sub, TASK, SPACE, ACQ, HEMI, DF_FILTER, CON\n",
    ") for sub in tqdm_notebook(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [i for i in imgs if i is not None]\n",
    "dm = pd.DataFrame({'icept': np.ones(len(imgs))})\n",
    "out = compute_rfx_contrast(\n",
    "    imgs=np.vstack(imgs),\n",
    "    design_matrix=dm,\n",
    "    contrast_def='icept',\n",
    "    stat_type='t'\n",
    ")\n",
    "\n",
    "plot_surface(out, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'anticipation'\n",
    "subs = glob(f'../derivatives/fmriprep/sub-*/func/sub-*_task-{TASK}*_space-T1w_desc-preproc_bold.json')[:200]\n",
    "subs = [op.basename(op.dirname(op.dirname(sub))).split('-')[1] for sub in subs]\n",
    "SPACE = 'fsaverage5'\n",
    "ACQ = 'seq'\n",
    "HEMI = 'R'\n",
    "DF_FILTER = partial(preproc_df, col='trial_type')\n",
    "CON = 'img_negative - img_neutral'\n",
    "\n",
    "imgs = Parallel(n_jobs=10)(delayed(_parallel_fit)(\n",
    "  sub, TASK, SPACE, ACQ, HEMI, DF_FILTER, CON\n",
    ") for sub in tqdm_notebook(subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [i for i in imgs if i is not None]\n",
    "dm = pd.DataFrame({'icept': np.ones(len(imgs))})\n",
    "out = compute_rfx_contrast(\n",
    "    imgs=np.vstack(imgs),\n",
    "    design_matrix=dm,\n",
    "    contrast_def='icept',\n",
    "    stat_type='t'\n",
    ")\n",
    "\n",
    "plot_surface(out, threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardiac_cols = [\n",
    "    'cardiac_cos_00', 'cardiac_sin_00', 'cardiac_cos_01', 'cardiac_sin_01', 'cardiac_cos_02', 'cardiac_sin_02'\n",
    "]\n",
    "resp_cols = [\n",
    "    'resp_cos_00', 'resp_sin_00', 'resp_cos_01', 'resp_sin_01', 'resp_cos_02', 'resp_sin_02', 'resp_cos_03', 'resp_sin_03'\n",
    "]\n",
    "\n",
    "interact_cols = [\n",
    "    'interaction_add_cos_00', 'interaction_add_sin_00', 'interaction_diff_cos_00', 'interaction_diff_sin_00'\n",
    "]\n",
    "ricor_cols = cardiac_cols + resp_cols + interact_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = pd.DataFrame({'icept': np.ones(len(imgs))})\n",
    "out = ds.gstroop.compute_rfx_contrast(\n",
    "    imgs=np.vstack(imgs),\n",
    "    design_matrix=dm,\n",
    "    contrast_def='icept',\n",
    "    stat_type='t'\n",
    ")\n",
    "ds.visualize(out, hemi='L', space='fsaverage5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '../sub-0010/func/sub-0010_task-gstroop_acq-seq_events.tsv', sep='\\t'\n",
    ")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
